# 主模型类型 local、aip、openai
MAIN_MODEL_TYPE=openai

#OPENAI模型服务框架ip:port/v1/completions
OPENAI_MODEL_HOST=""
# 模型请求模型的key,可选
# OPENAI_MODEL_AUTHORIZATION=""
#OPENAI模型名称
OPENAI_MODEL=DeepSeek-Coder-V2-Lite-Base
# 上下文请求完整路由
CODEBASE_RELATION_URL=""
# CODEBASE_DEFINITION_URL=""
CODEBASE_SEMANTIC_URL=""

CODEBASE_SEMANTIC_TOP_K=10
CODEBASE_SEMANTIC_SCORE_THRESHOLD=0.5

# 上下文总最长耗时(ms)
CONTEXT_COST_TIME=2000
# 上下文请求最长耗时,低于上下文总耗时
CONTEXT_REQUEST_TIMEOUT=1500
# 关闭上下文定义检索
DISABLE_CONTEXT_DEF_SEARCH=False
# 关闭上下文语义检索
DISABLE_CONTEXT_SEMANTIC=False


#过滤规则
#STR_PATTERN=" *class +.*| *def +.*|import +.*|from +.*|from +.* import *.*| *f'.*| *f\".*| *#.*"
#stop_words默认配置路径
STOP_WORD_JSON_PATH=/python-docker/config/stop_words.json

#prompt上下文长度限制
MAX_MODEL_LEN=4000,1000
# 模型最大响应时间，单位毫秒
MAX_MODEL_COST_TIME=2800
# 用户容忍耗时
MAX_COST_TIME=3500
# 模型输出最大Token
MAX_TOKENS=300
# 流式多行块级补全达到该行数阈值时候触发语法检查
MULTI_LINE_STREAM_K=8
# 隐藏分阈值
THRESHOLD_SCORE=0.3
# 引入关联上下文后，需保留最少prefix的token数
MIN_PREFIX_TOKEN=2000

# 关闭补全拒绝处理器
# DISABLED_REJECT_LANGUAGE_FEATURE=True
# DISABLED_AUTHORIZATION=True
# DISABLED_SCORE_REJECT=True

# Redis
ENABLE_REDIS=False
REDIS_HOST=127.0.0.1
REDIS_PORT=6379
REDIS_DB=0
REDIS_PWD=
COMPLETION_CACHE_TIME=86400

# 连续补全结果缓存时长（单位s）
CONTINUE_COMPLETION_CACHE_EXPIRED=30

# uvicorn
UVICORN_HOST=0.0.0.0
UVICORN_PORT=5000
UVICORN_WORKERS=2
UVICORN_BACK_LOG=128